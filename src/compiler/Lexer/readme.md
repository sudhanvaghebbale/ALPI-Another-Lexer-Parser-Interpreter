#### To generate tokens, save code in script.txt and run lexer.py the stream of tokens should be generated in tokens.txt


### TODO:
- [x] Lexer should be able to handle syntax errors.
- [x] Remove comments from input source.
- [x] Accomodated String declarations in source.
- [x] Output file readable by prolog Script.
- [x] Works with increment and decremnent operator.
- [x] Tokenizer doesn't tokenize ,.+-^|/\= so, need spaces between characters when declaring them. 
- [x] To make the lexer.py take filenames as arguments from shell to compile tokens on-the-go. 
- [ ] ~~Execute Multiple files at once?~~
- [x] Accomodate  (, {, [ for prolog script in lexer.


### Rules:

* When Writing Strings please make sure to include spaces between start quote and end quote eg: x = ' Hello '. 
* Strings inside print or declaration should always enclosed by single quotes, not other variation.



